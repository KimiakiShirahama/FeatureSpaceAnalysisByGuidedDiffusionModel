# FeatureSpaceAnalysisByGuidedDiffusionModel
This is the official implementation of the decoder introduced in the paper "Feature Space Analysis by Guided Diffusion Model" 

One of the key issues in Deep Neural Networks (DNNs) is the black-box nature of their internal feature extraction process. Targeting vision-related domains, this paper focuses on analysing the feature space of a DNN by developing a *decoder* that can generate images whose features are ensured to closely match a user-specified feature. Our decoder is especially implemented as a *guided diffusion model* that guides the reverse image generation of a pre-trained diffusion model to minimise the Euclidean distance between the feature of a clean image estimated at each step and the user-specified one. The main advantage of our decoder is that feature spaces of different DNNs can be analysed with no additional training using a single COTS GPU. The experimental results targeting CLIP's image encoder, ResNet-50 and vision transformer demonstrate that images generated by our decoder have features remarkably similar to the user-specified ones and reveal valuable insights into these DNNs' feature space

## High-resolution figures
We had to compress the following figures containing many images due to the file size limitation during the paper preparation. Please click the links below to see the high-resolution versions: 
- [Figure 3](https://xxx)
- [Figure 4](https://xxx)
- [Figure 5](https://xxx)
- [Figure 6](https://xxx)
- [Figure 7](https://xxx)
- [Figure 8](https://xxx)
- [Figure 9](https://doshishaacjp-my.sharepoint.com/:b:/g/personal/kshiraha_mail_doshisha_ac_jp/EYvKeYjCbHBKhtTiUodXJ6QBFYtUzIzsLHFwf66OKCcguA?e=ANYCNB)
- [Figure 11](https://doshishaacjp-my.sharepoint.com/:b:/g/personal/kshiraha_mail_doshisha_ac_jp/EURmEACQRlREp9uJpZkKvL0B6ple-gs-D3UpkXbqOwsHRw)
